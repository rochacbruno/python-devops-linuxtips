---
title: Analisador de Logs com Python
sub_title: Desenvolvendo o Logan - Log Analyzer
author: Python para DevOps
options:
  implicit_slide_ends: true
  end_slide_shorthand: true
  incremental_lists: true
---

O Problema
===

- O site est√° lento
- Voc√™ tem um arquivo de log de *50GB*
- Como descobrir R√ÅPIDO qual endpoint est√° causando problema?


Como Resolver?
===

<!-- alignment: center -->

```bash
# grep? 
grep "500" /var/log/nginx/access.log
```


‚úÖ Funciona para buscar erros

‚ùå N√£o conta, n√£o agrupa, n√£o d√° estat√≠sticas


```bash
# awk?
awk '{print $9}' access.log | sort | uniq -c
```


‚úÖ Poderoso

‚ùå Sintaxe complexa, dif√≠cil de expandir


Logan: Log Analyzer
===

<!-- font_size: 2 --> 
<!-- alignment: center -->


Nossa miss√£o hoje: criar um analisador de logs que:

<!-- incremental_lists: true -->

* Processe arquivos **gigantes** sem travar
* Extraia **insights √∫teis** automaticamente
* Seja **extens√≠vel** para diferentes formatos
* Use apenas Python **b√°sico**



O Problema da Mem√≥ria
===

<!-- alignment: center --> 

## ‚ùå Abordagem ing√™nua

```python
# N√ÉO FA√áA ISSO!
def read_log_bad(filename):
    with open(filename, 'r') as f:
        lines = f.readlines()  # 50GB na RAM! üí•
    return lines
```

## ‚úÖ Abordagem correta

```python
# Leitura linha por linha
def read_log_good(filename):
    with open(filename, 'r') as f:
        for line in f:  # Iterator! 
            yield line     # Uma linha por vez
```

Por que `with open()`?
===

```python
# Jeito antigo (perigoso)
f = open('arquivo.log')
dados = f.read()
# E se der erro? Arquivo fica aberto!
f.close()
```



```python
# Jeito Pyth√¥nico (seguro)
with open('arquivo.log') as f:
    dados = f.read()
# Arquivo SEMPRE ser√° fechado
```

<!-- alignment: center --> 

**Context Manager**: garante limpeza autom√°tica! üßπ



Vers√£o 1: MVP
===

```python +exec
# logan_v1.py
import sys

def analyze_logs(file_handle):
    line_count = 0
    for line in file_handle:
        line_count += 1
    
    print(f"Total de linhas: {line_count}")

# Simular execu√ß√£o
from io import StringIO
fake_log = StringIO("linha1\nlinha2\nlinha3\n")
analyze_logs(fake_log)
```

<!-- alignment: center -->





Flexibilidade de Entrada
===

<!-- alignment: center -->

```python
if __name__ == "__main__":
    # Suporta arquivo ou stdin
    if len(sys.argv) > 1:
        with open(sys.argv[1], 'r') as f:
            analyze_logs(f)
    else:
        analyze_logs(sys.stdin)
```

## Formas de usar:

```bash
# M√©todo 1: Arquivo direto
uv run loganv1.py access.log

# M√©todo 2: Pipeline Unix
cat access.log | uv run loganv1.py

# Redirecionamento
uv run loganv1.py < access.log 
```

## Simplificando 

```python
if __name__ == "__main__":
    file = sys.argv[1] if len(sys.argv) > 1 else 0
    with open(file) as f:
        analyze_logs(f)
```

Arquivo vs STDIN
===

<!-- column_layout: [1, 1] -->

<!-- column: 0 -->

## üìÅ Arquivo Direto

### Vantagens:
* Seek poss√≠vel
* Mais controle

### Desvantagens:
* Precisa acesso ao arquivo
* Python vai ter que fazer mmap buffering 

<!-- column: 1 -->

## üîÄ Via STDIN

### Vantagens:
* Composi√ß√£o Unix
* Filtros pr√©vios
* Streaming real-time
* Buffer controlado pelo SO

### Desvantagens:
* Sem seek
* Menos controle sobre fonte



Comparando
===

<!-- column_layout: [1, 1] -->
<!-- column: 0 -->


Abra o vim e digite a seguinte combina√ß√£o em sequencia:

```
10001oHello World<Esc>
```
Aguarde um pouco e o vim vai criar um arquivo com 10.001 linhas "Hello World".  
Agora salve o arquivo `:w text`

```bash {1-7|8-11|13-18}
$ apt install time

$ /usr/bin/time -f "%M" uv run loganv1.py < text
# Output:
# Total de linhas: 10001
> 37796

$ /usr/bin/time -f "%M" uv run loganv1.py text
# Output:
# Total de linhas: 10001
> 37720

$ /usr/bin/time -f "%M" bash -c "cat text | uv run loganv1.py"
# Output:
> 1516
# Total de linhas: 10001
```

<!-- column: 1 -->

### Mem√≥ria usada (KB):

* Arquivo direto: ~37MB
* Via redirecionamento: ~37MB
* Via pipe: ~1.5MB

**Por qu√™?**

- Arquivo direto precisa de Buffer I/O e mmap, o file descriptor para gerenciar o arquivo aberto acaba consumindo mais espa√ßo pois precisa manter mais informa√ß√µes.
- Via Pipe o `cat` detecta que o `stdout` em uso n√£o √© um termimal (tty) e ent√£o utiliza buffering. 
- O sistema operacional gerencia o buffer de forma mais eficiente, o Kernel gerencia o tamanho do buffer, liberando mem√≥ria conforme necess√°rio, o Python n√£o tem outra op√ß√£o a n√£o ser ler o que vem chunck a chunk do pipe, n√£o tem o mesmo controle mas √© mais eficiente em termos de mem√≥ria.

D√° para melhorar?
```python {3}
if __name__ == "__main__":
    file = sys.argv[1] if len(sys.argv) > 1 else 0
    with open(file, buffering=1) as f:
        analyze_logs(f)
```

Ou usar low level `os.read` ou unbuffered I/O com `io.TextIOWrapper` pois com essa abordagem podemos controlar exatamente o tamanho dos chunks lidos pelo python, reduzindo o overhead de mem√≥ria.

Anatomia de um Log NGINX
===

<!-- alignment: center --> 


```
192.168.1.10 - - [01/Jan/2024:10:15:23 +0000] "GET /api/users HTTP/1.1" 200 2326
```

<!-- font_size: 2 --> 

<!-- incremental_lists: true -->

* **IP**: `192.168.1.10`
* **Timestamp**: `01/Jan/2024:10:15:23 +0000`
* **M√©todo**: `GET`
* **Endpoint**: `/api/users`
* **Status**: `200`
* **Tamanho**: `2326` bytes
* **Referrer**: (opcional) 
* **User-Agent**: (opcional)
* **Response Time**: (opcional)

**Log de Exemplo**: 


Vers√£o 2: Parser com Regex
===

```python {1-6|8-12}
import re

LOG_PATTERN = re.compile(
    r'(?P<ip>\S+) \S+ \S+ \[(?P<datetime>[^\]]+)\] '
    r'"(?P<method>\S+) (?P<path>\S+) (?P<protocol>\S+)" '
    r'(?P<status>\d+) (?P<size>\S+)'
)

def parse_line(line):
    match = LOG_PATTERN.match(line)
    if match:
        return match.groupdict()
    return None
```

<!-- alignment: center --> 

**Grupos nomeados** = c√≥digo mais leg√≠vel! üìñ



O Poder do Counter
===

```python +exec +line_numbers {1|3-10|12-17|19-23}
log = ['/api', '/api', '/home', '/api', '/contact', '/home', '/contact']

# Acumulando manualmente
endpoints = {}
for endpoint in log:
    if endpoint in endpoints:
        endpoints[endpoint] += 1
    else:
        endpoints[endpoint] = 1
print("Manual:", endpoints)

# Com DefaultDict
from collections import defaultdict
endpoints = defaultdict(int)
for endpoint in log:
    endpoints[endpoint] += 1
print("DefaultDict:", dict(endpoints))

# Com Counter (Pyth√¥nico!)
from collections import Counter
endpoints = Counter(log)
print("Counter:", endpoints)
print("Top 2:", endpoints.most_common(2))
```

Vers√£o Final: An√°lise Completa
===

```python +line_numbers {1|3-7|9-22|24-30}
def analyze_logs(file_handle, verbose=False):
    # Contadores eficientes
    endpoint_counter = Counter()
    status_counter = Counter()
    error_endpoints = defaultdict(int)
    total_lines = 0
    valid_lines = 0

    for line_num, line in enumerate(file_handle, 1):
        total_lines = line_num
        if verbose and line_num % 10000 == 0:
            print(f"Processadas {line_num:,} linhas...", file=sys.stderr)

        if parsed := parse_line(line.strip()):
            valid_lines += 1
            # Coleta estat√≠sticas
            endpoint = parsed["path"]
            status = int(parsed["status"])
            endpoint_counter[endpoint] += 1
            status_counter[status] += 1
            if status >= 400:
                error_endpoints[endpoint] += 1

    return {
        "total_lines": total_lines,
        "valid_lines": valid_lines,
        "endpoints": endpoint_counter,
        "status_codes": status_counter,
        "error_endpoints": dict(error_endpoints),
    }
```



Relat√≥rio Visual
===

<!-- column_layout: [1, 2] -->

<!-- column: 0 -->

```
=====================================
RELAT√ìRIO DE AN√ÅLISE DE LOGS - LOGAN
=====================================

üìä ESTAT√çSTICAS GERAIS:
   Total de linhas: 1,234,567
   Linhas v√°lidas: 1,234,000

üéØ TOP 10 ENDPOINTS MAIS ACESSADOS:
   450,123 - /api/users
   234,567 - /api/products
   123,456 - /

‚ùå TOP 5 ENDPOINTS COM MAIS ERROS:
    12,345 - /api/orders
     5,432 - /api/payment

üìà DISTRIBUI√á√ÉO DE STATUS HTTP:
   200: 900,000 (72.9%)
   404: 123,456 (10.0%)
   500:  12,345 (1.0%)
```

<!-- column: 1 -->
<!-- pause --> 
```python +line_numbers {2-5|7-9|11-14|15-24|25-29|30}
def generate_report(stats):
    report = []
    report.append("=" * 50)
    report.append("RELAT√ìRIO DE AN√ÅLISE DE LOGS - LOGAN")
    report.append("=" * 50)
    report.append("")
    report.append("üìä ESTAT√çSTICAS GERAIS:")
    report.append(f"   Total de linhas: {stats['total_lines']:,}")
    report.append(f"   Linhas v√°lidas: {stats['valid_lines']:,}")
    report.append("")
    report.append("üéØ TOP 10 ENDPOINTS MAIS ACESSADOS:")
    for endpoint, count in stats["endpoints"].most_common(10):
        report.append(f"   {count:,} - {endpoint}")
    report.append("")
    if stats["error_endpoints"]:
        report.append("‚ùå TOP 5 ENDPOINTS COM MAIS ERROS:")
        error_sorted = sorted(
            stats["error_endpoints"].items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:5]
        for endpoint, count in error_sorted:
            report.append(f"    {count:,} - {endpoint}")
        report.append("")
    report.append("üìà DISTRIBUI√á√ÉO DE STATUS HTTP:")
    total_requests = sum(stats["status_codes"].values())
    for status, count in sorted(stats["status_codes"].items()):
        percentage = (count / total_requests) * 100
        report.append(f"   {status}: {count:,} ({percentage:.1f}%)")
    return "\n".join(report)
```

D√° para melhorar?
===

![](logan.png)


UV Script Dependencies
===

<!-- column_layout: [1, 1] -->
<!-- column: 0 -->

```bash
touch loganv3.py
uv add --script loganv3.py rich
```
```python
‚ùØ cat loganv3.py
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "rich",
# ]
# ///
```

<!-- column: 1 -->

```python +exec
# /// script
# requires-python = ">=3.13"
# dependencies = [
#     "rich",
# ]
# ///
from rich.console import Console
from rich.table import Table

console = Console()
table = Table(show_header=True, header_style="bold magenta")
table.add_column("Name", style="dim", width=12)
table.add_column("Age", justify="right")
table.add_column("City", justify="right")
table.add_row("Alice", "24", "New York")
table.add_row("Bob", "19", "Los Angeles")
table.add_row("Charlie", "22", "Chicago")
console.print(table)
```


Logan com Rich
===


```python +line_numbers {1-6|9-11|12-22|23-30}
status_table = Table(title="üìà DISTRIBUI√á√ÉO DE STATUS HTTP", box=box.ROUNDED)
status_table.add_column("Status", justify="center", style="cyan", width=8)
status_table.add_column("Tipo", style="dim")
status_table.add_column("Requisi√ß√µes", justify="right", style="yellow")
status_table.add_column("Porcentagem", justify="right", style="green")
status_table.add_column("Barra", style="blue")
total_requests = sum(stats["status_codes"].values())
max_count = max(stats["status_codes"].values()) if stats["status_codes"] else 1
for status, count in sorted(stats["status_codes"].items()):
    percentage = (count / total_requests) * 100
    bar_length = int((count / max_count) * 20)
    bar = "‚ñà" * bar_length + "‚ñë" * (20 - bar_length)
    if 200 <= status < 300:
        status_type, status_style = "‚úÖ OK", "[green]"
    elif 300 <= status < 400:
        status_type, status_style = "‚Ü™Ô∏è Redirect", "[yellow]"
    elif 400 <= status < 500:
        status_type, status_style = "‚ö†Ô∏è Client Error", "[orange1]"
    elif 500 <= status < 600:
        status_type, status_style = "‚ùå Server Error", "[red]"
    else:
        status_type, status_style = "‚ùì Unknown", "[dim]"
    status_table.add_row(
        f"{status_style}{status}[/]", 
        status_type, 
        f"{count:,}", 
        f"{percentage:.1f}%", 
        bar
    )
console.print(status_table)
```

Resultado 
===

```
                         üìà DISTRIBUI√á√ÉO DE STATUS HTTP                          
‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ
‚îÇ  Status  ‚îÇ Tipo            ‚îÇ Requisi√ß√µes ‚îÇ Porcentagem ‚îÇ Barra                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ   200    ‚îÇ ‚úÖ OK           ‚îÇ           8 ‚îÇ        8.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   201    ‚îÇ ‚úÖ OK           ‚îÇ           6 ‚îÇ        6.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   204    ‚îÇ ‚úÖ OK           ‚îÇ           5 ‚îÇ        5.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   301    ‚îÇ ‚Ü™Ô∏è Redirect     ‚îÇ           5 ‚îÇ        5.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   302    ‚îÇ ‚Ü™Ô∏è Redirect     ‚îÇ           6 ‚îÇ        6.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   304    ‚îÇ ‚Ü™Ô∏è Redirect     ‚îÇ           8 ‚îÇ        8.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   400    ‚îÇ ‚ö†Ô∏è Client Error ‚îÇ          10 ‚îÇ       10.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   401    ‚îÇ ‚ö†Ô∏è Client Error ‚îÇ           9 ‚îÇ        9.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   403    ‚îÇ ‚ö†Ô∏è Client Error ‚îÇ           8 ‚îÇ        8.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   404    ‚îÇ ‚ö†Ô∏è Client Error ‚îÇ           3 ‚îÇ        3.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   500    ‚îÇ ‚ùå Server Error ‚îÇ           9 ‚îÇ        9.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   502    ‚îÇ ‚ùå Server Error ‚îÇ          10 ‚îÇ       10.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë‚ñë‚ñë ‚îÇ
‚îÇ   503    ‚îÇ ‚ùå Server Error ‚îÇ          13 ‚îÇ       13.0% ‚îÇ ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà ‚îÇ
‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ
```

<!-- alignment: center -->
Exceute `head -n 100000 sample_nginx.log | uv run loganv3.py` para ver o Logan em a√ß√£o!


O que mais d√° para fazer?
===

<!-- alignment: center -->

Filtrar endpoints
```bash
# uv run
loganv3.py --filter "/api/*"
```

Filtrar status
```bash
# uv run
loganv3.py --status ">=400"
```

Escolher colunas *
```bash
# uv run
loganv3.py --columns "status,count,percentage"
```

Formatos de sa√≠da *
```bash
# uv run
loganv3.py --output json
```

Precisamos implementar de tudo isso?
===

<!-- alignment: center -->

<!-- pause --> 

**Unix Philosophy**: Fa√ßa uma coisa e fa√ßa bem feita! üõ†Ô∏è

<!-- pause --> 

```bash
grep -E '" 4[0-9]{2} ' nginx_sample.log | head -n 1000 | uv run loganv3.py
```

<!-- pause --> 

![](grep_filter_logan.png)


Aplica√ß√£o no Mundo Real
===

## üö® Detec√ß√£o de ataques

```python
# IPs com muitas requisi√ß√µes
ip_counter = Counter()
for parsed in log_entries:
    ip_counter[parsed['ip']] += 1

suspicious = [ip for ip, count in ip_counter.items() 
              if count > 1000]
```



## üìä An√°lise de performance

```python
# Endpoints lentos (status 504)
slow_endpoints = [e for e in endpoints 
                  if e['status'] == 504]
```



<!-- jump_to_middle -->

Conclus√£o
===

<!-- font_size: 2 -->

1. Sempre pense em **escalabilidade**
2.  **Context managers** para lidar com recursos
3.  Python tem **ferramentas poderosas** na stdlib
4. Use a **filosofia Unix** a seu favor
5. Ferramentas como **Rich** melhoram UX dramaticamente
6. **UV** pode gerenciar depend√™ncias em scripts

